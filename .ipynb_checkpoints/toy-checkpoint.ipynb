{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Name:** \n",
    "\n",
    "**EID:** \n",
    "\n",
    "**Kaggle Team Name:** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS4487 - Course Project: Aerial Cactus Identification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "In this project, your goal is to train a classifier to predict whether an input image contains cactus.\n",
    "\n",
    "\n",
    "## Methodology\n",
    "You need to train classifiers using the training data, and then predict on the test data. You are free to choose the feature extraction method and classifier algorithm.  You are free to use methods that were not introduced in class.  You should probably do cross-validation to select a good parameters.\n",
    "\n",
    "\n",
    "## Evaluation on Kaggle\n",
    "\n",
    "You need to submit your test predictions to Kaggle for evaluation.  50% of the test data will be used to show your ranking on the live leaderboard.  After the assignment deadline, the remaining 50% will be used to calculate your final ranking. \n",
    "\n",
    "To submit to Kaggle you need to create an account, and use the competition invitation that will be posted on Canvas.\n",
    "\n",
    "**Note:** You can only submit 2 times per day to Kaggle!\n",
    "\n",
    "\n",
    "\n",
    "## Kaggle Notebooks\n",
    "\n",
    "You can use Kaggle notebooks to run your code. This ipynb has also been uploaded to the Kaggle competition site. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class labels `\"1\"` for images containing cactus and `\"0\"` for others.\n",
    "\n",
    "To submit to Kaggle, you need to generate a Kaggle submission files, which is CSV file with the following format. `'id'` is the file name of the input image: \n",
    "\n",
    "<pre>\n",
    "Id,Prediction\n",
    "cactus_0181_18.jpg,1\n",
    "Sinplanta.4365.jpg,0\n",
    "...\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are two helpful functions for reading the data and writing the Kaggle submission file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import IPython.core.display         \n",
    "# setup output image format (Chrome works best)\n",
    "IPython.core.display.set_matplotlib_formats(\"svg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from numpy import *\n",
    "from sklearn import *\n",
    "from glob import glob\n",
    "from scipy import stats\n",
    "import csv\n",
    "import os\n",
    "random.seed(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_train_data():\n",
    "    cactus_imgs = glob(\"training_set/training_set/cactus/*\")\n",
    "    cactus_labels = ones(len(cactus_imgs), dtype=int)\n",
    "    nocactus_imgs = glob(\"training_set/training_set/no_cactus/*\")\n",
    "    nocactus_labels = zeros(len(nocactus_imgs), dtype=int)\n",
    "\n",
    "    train_X = cactus_imgs + nocactus_imgs\n",
    "    train_Y = hstack((cactus_labels, nocactus_labels))\n",
    "    return train_X, train_Y\n",
    "\n",
    "def read_test_data():\n",
    "    return glob(\"validation_set/*/*/*\")\n",
    "\n",
    "def write_csv_kaggle_sub(fname, X, Y):\n",
    "    # fname = file name\n",
    "    # X is a list with image names\n",
    "    # Y is a list/array with class entries\n",
    "    \n",
    "    # header\n",
    "    tmp = [['Id', 'Prediction']]\n",
    "    \n",
    "    # add ID numbers for each Y\n",
    "    for x,y in zip(X, Y):\n",
    "        tmp2 = [x, y]\n",
    "        tmp.append(tmp2)\n",
    "        \n",
    "    # write CSV file\n",
    "    with open(fname, 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_set/training_set/cactus/cactus_0028_0.jpg 1\n",
      "training_set/training_set/no_cactus/Sinplanta.2677.jpg 0\n",
      "4000\n",
      "cactus_0181_18.jpg\n"
     ]
    }
   ],
   "source": [
    "train_X, train_Y = read_train_data()\n",
    "print(train_X[0], train_Y[0])\n",
    "print(train_X[15000], train_Y[15000])\n",
    "\n",
    "test_X = read_test_data()\n",
    "print(len(test_X))\n",
    "print(os.path.basename(test_X[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example to write a csv file with predictions on the test set.  These are random predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your predictions on the test set\n",
    "dummy_test_X = [os.path.basename(x) for x in test_X]\n",
    "test_Y = random.randint(2, size=len(test_X))\n",
    "\n",
    "write_csv_kaggle_sub(\"my_submission.csv\", dummy_test_X, test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOUR CODE and DOCUMENTATION HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-process to img vector\n",
    "# seperate dataset training seperate validation set\n",
    "# PCA, SVD for dimention reduction\n",
    "# SVM\n",
    "# logistic regression\n",
    "\n",
    "# trainX, testX, trainY, testY = \\\n",
    "#   model_selection.train_test_split(train_X, train_Y, \n",
    "#   train_size=0.80, test_size=0.20)\n",
    "\n",
    "# img = matplotlib.image.imread(train_X[0])\n",
    "# print(img.shape)\n",
    "# plt.imshow(img, cmap='gray', interpolation='nearest')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to seperate whole training dataset into two parts - training set and validation set. We are using 90% of the whole training data for training and 10% for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, valX, trainY, valY = \\\n",
    "  model_selection.train_test_split(train_X, train_Y, \n",
    "  train_size=0.90, test_size=0.10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we are going to define hyper parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "\n",
    "num_epochs = 10\n",
    "num_classes = 2\n",
    "batch_size = 25\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we have to define our torch dataset class for getting images and data. In the getitem function, we have to preprocess our image so that all of our images have the same size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, label, transform=None):\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_name = self.data[index]\n",
    "        label = self.label[index]\n",
    "        image = plt.imread(img_name)\n",
    "        image = cv2.resize(image, (32, 32),  \n",
    "               interpolation = cv2.INTER_CUBIC) \n",
    "        image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "trainDataset = Dataset(data=trainX, label=trainY, transform=transforms.ToTensor())\n",
    "valDataset = Dataset(data=valX, label=valY, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the below code, we define loaders for training and validation respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_train = DataLoader(dataset = trainDataset, \n",
    "                          batch_size=batch_size, \n",
    "                          shuffle=True,\n",
    "                          num_workers=0)\n",
    "\n",
    "loader_valid = DataLoader(dataset = valDataset,\n",
    "                          batch_size=batch_size//2, \n",
    "                          shuffle=False, \n",
    "                          num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, we are going to define a CNN network for training. I use two conv layer in the CNN. Each conv layer is followed by a max_pool2d and relu function. For the second conv layer, I use a Dropout2d for reducing the issue of overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module): \n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=10, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=3)\n",
    "        self.fc1 = nn.Linear(720, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 2)\n",
    "        self.drop = nn.Dropout2d()\n",
    "\n",
    "    def forward(self, t):\n",
    "        # conv layer 1\n",
    "        t = self.conv1(t)\n",
    "        t = F.max_pool2d(t, 2)\n",
    "        t = F.relu(t)\n",
    "        \n",
    "        # conv layer 2\n",
    "        t = self.conv2(t)\n",
    "        t = self.drop(t)\n",
    "        t = F.max_pool2d(t, 2)\n",
    "        t = F.relu(t)\n",
    "        \n",
    "        t = t.view(t.shape[0],-1)\n",
    "        t = F.relu(self.fc1(t))\n",
    "        t = F.dropout(t, training=self.training)\n",
    "        t = self.fc2(t)\n",
    "        \n",
    "        return t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we are going to define the loss function and optimizer. I use BCEWithLogitsLoss as it is a binary classifier. I also use Adamax for optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN()\n",
    "# Loss function and optimizer\n",
    "loss_func = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adamax(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are going to train the model. We also include evalulation in the loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \tTraining Loss: 0.322851 \tValidation Loss: 0.187844\n",
      "Epoch: 1 \tTraining Loss: 0.205717 \tValidation Loss: 0.167428\n",
      "Epoch: 2 \tTraining Loss: 0.179427 \tValidation Loss: 0.145515\n",
      "Epoch: 3 \tTraining Loss: 0.160858 \tValidation Loss: 0.134570\n",
      "Epoch: 4 \tTraining Loss: 0.148664 \tValidation Loss: 0.135722\n",
      "Epoch: 5 \tTraining Loss: 0.135902 \tValidation Loss: 0.123349\n",
      "Epoch: 6 \tTraining Loss: 0.131787 \tValidation Loss: 0.116905\n",
      "Epoch: 7 \tTraining Loss: 0.127097 \tValidation Loss: 0.114553\n",
      "Epoch: 8 \tTraining Loss: 0.123734 \tValidation Loss: 0.113365\n",
      "Epoch: 9 \tTraining Loss: 0.118302 \tValidation Loss: 0.113013\n"
     ]
    }
   ],
   "source": [
    "total_step = len(loader_train)\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    model.train()\n",
    "    for i, batch in enumerate(loader_train):\n",
    "        images = batch[0]\n",
    "        labels = batch[1]\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)[:,0]\n",
    "        loss = loss_func(outputs.float(), labels.float())\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "        \n",
    "#         if (i+1) % 100 == 0:\n",
    "#             print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "#                    .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "    # validate-the-model\n",
    "    model.eval()\n",
    "    for i, batch in enumerate(loader_valid):\n",
    "        \n",
    "        images = batch[0]\n",
    "        labels = batch[1]\n",
    "        \n",
    "        outputs = model(images)[:,0]\n",
    "        \n",
    "        loss = loss_func(outputs.float(), labels.float())\n",
    "        \n",
    "        # update-average-validation-loss \n",
    "        valid_loss += loss.item() * images.size(0)\n",
    "    \n",
    "    # calculate-average-losses\n",
    "    train_loss = train_loss/len(loader_train.sampler)\n",
    "    valid_loss = valid_loss/len(loader_valid.sampler)\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "        \n",
    "    # print-training/validation-statistics \n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "        epoch, train_loss, valid_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 4000 test images: 3.6571428571428575 %\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in loader_valid:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Test Accuracy of the model on the 4000 test images: {} %'.format((correct / total) * 100))\n",
    "\n",
    "# Save the model and plot\n",
    "torch.save(model.state_dict(), 'conv_net_model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
